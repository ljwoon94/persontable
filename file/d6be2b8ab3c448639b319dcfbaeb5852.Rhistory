car_model = lm(dist~speed, data=cars)
summary(car_model)
rpart
library(rpart)
iris
head(iris)
r = rpart(Species~.,data=iris)
rm(list=ls())
library(rpart)
r =rpart(Species.~,data= iris)
r =rpart(Species~.,data= iris)
r
print(r)
par(mfrow = c(1,1),xpd = NA)
plot(r)
text(r,use.n = TRUE)
p = predict(r, iris, type = 'class')
table(p,iris$Species)
p = predict(r, iris, type = 'prob')
table(p,iris$Species)
p = predict(r, iris, type = 'class')
table(p,iris$Species)
p = predict(r, iris, type = 'prob')
p
p = predict(r, iris, type = 'class')
table(p,iris$Species)
r_prior = rpart(Species~.,data=iris, parms = list(prior = c(0.1,0.1,0.8)))
plot(r_prior)
text(r,prior)
text(r_prior)
text(r_prior,use.n=TRUE)
plot(r_prior)
text(r_prior,use.n=TRUE)
newd= data.frame(Sepal.Length=c(5.11,7.01,6.32),Sepal.Width = c(3.51,3.2,3.31), Petal.Length=c(1.4,4.71,6.02), Petal.Width = c(0.19,1.4,2.49))
newd
print(newd)
predict(r, newdata = newd)
summary(r)
library(rpart.plot)
install.packages("raprt.plot")
library(rpart.plot)
library("rpart.plot")
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(r)
rpart.plot(r,type = 4)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(randomForest)
f=randomForest(Species~.,data=iris)
f
summary(f)
f
f
plot(f)
varUsed(f)
varImpPlot(f)
predict(newd)
predict(f,newdata = newd)
predict(f,newdata = newd,type=newd)
predict(f,newdata = newd,type='prob')
predict(f,newdata = newd, type = 'vote', norm.votes = FALSE)
small_forest= randomForest(Species~.,data=iris, ntree=20,nodesize=6,maxnodes=12)
treesize(small_forest)
small_forest
library(e1071)
install.packages("e1071")
library(e1071)
s =svm(Species~.,data=iris)
s
table(predict(s, iris), iris$Species)
s =svm(Species~.,data=iris,kernel = 'polynomial')
p=predict(s,iris)
table(p, iris$Species)
plot(s)
plot(p)
plot(p,s)
s =svm(Species~.,data=iris,cost=100)
p=predict(s,iris)
table(p, iris$Species)
s =svm(Species~.,data=iris,kernel=sigmoid)
s =svm(Species~.,data=iris,kernel='sigmoid')
p=predict(s,iris)
table(p, iris$Species)
train
library(class)
train=iris
test = data.frame(Sepal.Length = c(5.11,7.01,6.32), Sepal.Width = c(3.51,3.2,3.31),Petal.Length= c(1.4,4.71,6.02), Petal.Width=c(0.19,1.4,2.49))
k=knn(train[,1:4],test,train$Species,k=5)
k
library(caret)
install.packages("caret")
library(caret)
library(e1071)
s=svm(Species~.,data=iris)
s
s=svm(Species~.,data=iris,cost=100)
s
library(class)
train=iris
test
k=knn(train[,1:4],test, train$Species,k=5)
k
View(r)
View(r)
View(newd)
?knn
library(caret)
r=train(Species~.,data=iris, method='rpart')
r=train(Species~.,data=iris, method='rf')
r=train(Species~.,data=iris, method='svmRadial')
r=train(Species~.,data=iris, method='rpart')
f=train(Species~.,data=iris, method='rf')
s=train(Species~.,data=iris, method='svmRadial')
k=train(Species~.,data=iris, method='knn')
names(getModelInfo())
s
k
r
f
k
ucla=read.csv('http://stats.idre.ucla.edu/stat/data/binary.csv')
ucla=read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
ucla
ucla=read.csv('C:/R/r_ex/binary.csv')
str(ucla)
ucla$admit = factor(ucla$admit)
r =rpart(admit~.,data=ucla)
library(rpart)
r =rpart(admit~.,data=ucla)
r
par(mfrow=c(1,1),xpd=NA)
plot(r)
text(r, use.n=TRUE)
p=predict(r,ucla,type='class')
p
table(p,ucla$admit)
f=randomForest(admit~.,data=ucla)
library(randomForest)
f=randomForest(admit~.,data=ucla)
f
p=predict(r,ucla,type='vote')
p=predict(r,ucla,type='prob')
p
p=predict(r,ucla,type='vector')
p
p=predict(r,ucla,type='class')
p
f
library(survival)
clean_colon =na.omit(colon)
clean_colon =clean_colon[c(TRUE,FALSE),]
clean_colon$status = factor(clean_colon$status)
str(clean_colon)
r=rpart(status~., data = clean_colon)
p = predict(r, clean_colon,type ='class')
table(p,clean_colon$status)
plot(r)
text(r,use.n = TRUE)
summary(r)
f=randomForest(status~rx+sex+age+obstruct+perfor+adhere+nodes+differ+extent+surg+node4, data=clean_colon)
f
r=rpart(status~rx+sex+age+obstruct+perfor+adhere+nodes+differ+extent+surg+node4, data=clean_colon)
p=predict(r,clean_colon,type='class')
table(p,clean_colon$status)
plot(r)
text(r,use.n = TRUE)
summary(r)
f
voice=read.csv('C:/Sources/voice.csv')
treesize(f)
n=nrow(iris)
i=1:n
train_list=sample(i,n*0.6)
test_list=setdiff(i,train_list)
iris_train=iris[train_list, ]
iris_test=iris[train_list, ]
iris_test=iris[test_list, ]
f=randomForest(Species~.,data=iris_train)
p=predict(f, newdata=iris_test)
p
iris_test$Species
library(caret)
train_list =createDataPartition(y=iris$Species, p =0.6,list=FALSE)
iris_train = iris[train_list, ]
iris_test = iris[-train_list, ]
f=randomForest(Species~.,data=iris_train)
p=predict(f,newdata=iris_test)
data= iris[sample(nrow(iris)),]
k=5
q=nrow(data)/k
l=1:nrow(data)
accuracy=0
for(i in 1:k) {}
for(i in 1:k) {
test_list=((i-1)*q+1):(i*q)
testData=data[test_list, ]
train_list=setdiff(l,test_list)
trainData= data[train_list, ]
f=train(Species~., data=trainData, method='rf')
p=predict(f, newdata= testData)
t=table(p, testData$Species)
accuracy=accuracy+(t[1,1]+t[2,2]+t[3,3])/length(test_list)
}
(average_accuracy-accuracy/k)
(average_accuracy=accuracy/k)
library(caret)
data=iris[sample(nrow(iris)), ]
k=5
q=nrow(data)/k
l=1:nrow(data)
accuracy=0
for(i in 1:k) {
}
control = trainControl(method='cv', number=5)
r=train(Species~.,data=iris, method='rpart',metric='Accuracy',trControl=control)
f=train(Species~.,data=iris, method='rf', metric='Accuracy', trControl=control)
s=train(Species~.,data=iris, method='svmRadial', metric='Accuracy', trControl=control)
k=train(Species~.,data=iris, method='knn', metric='Accuracy', trControl=control)
resamp=resamples(list(결정트리=r , 랜덤포리스트=f,SVM=s,kNN=k))
View(resamp)
summary(resamp)
sort(resamp, decreasing = TRUE)
dotplot(resamp)
library(survival)
clean_colon=na.omit(colon)
clean_colon=clean_colon[c(TRUE,FALSE), ]
clean_colon$status = factor(clean_colon$status)
library(ROCR)
install.packages("ROCR")
library(ROCR)
labels = c(0,0,1,0,1,0,0,0,1)
prediction = c(0.26,0.81,0.73,0.11,0.20,0.48,0.23,0.11,0.61,0.99)
p=prediction(predictions, labels)
predictions = c(0.26,0.81,0.73,0.11,0.20,0.48,0.23,0.11,0.61,0.99)
p=prediction(predictions, labels)
p=prediction(predictions, labels)
labels = c(0,0,1,0,1,1,0,0,0,1)
p=prediction(predictions, labels)
p
roc = performance(p,measure='tpr', x.meas\)
roc = performance(p,measure='tpr', x.measure='fpr')
plot(roc)
abline(a=0,b=1)
auc=performance(p,measure='auc')
auc@y.values
p
summary(p)
library(RCurl)
library(XML)
install.packages("RCurl")
install.packages("XML")
t=readLines('https://en.wikipedia.org/wiki/Data_science')
d=htmlParse(t,asText=TRUE)
d=htmlParse(t, asText=TRUE)
library(RCurl)
library(XML)
d=htmlParse(t, asText=TRUE)
clean_doc =xpathSApply(d,"//p",xmlValue)
library(tm)
install.packages(tm)
install.packages("tm")
install.packages(tm)
library(tm)
library(SnowballC)
install.packages("SnowballC")
library(SnowballC)
doc = Corpus(VectorSource((clean_doc)))
inspect(doc)
doc = tm_map(doc, content_transformer(tolower))
doc = tm_map(doc, removeNumbers
)
doc
doc = tm_map(doc, removeWords
, stopwords('english'))
doc = tm_map(doc, removePunctuation)
doc = tm_map(doc, stripWhitespace)
dtm = DocumentRermMatrix(doc)
dtm = DocumentTermMatrix(doc)
dim(dtm)
inspect(dtm)
doc
library(tm)
library(SnowballC)
doc=Corpus(VectorSource(clean_doc))
inspect(doc)
library(wordcloud)
install.packages(wordcloud)
library(wordcloud)
library("wordcloud")
install.packages("wordcloud")
library(wordcloud)
m=as.matrix(dtm)
dtm
v=sort(colSums(m),decreasing = TRUE)
d=data.frame(word=names(v),freq=v)
wordcloud(words=d$word, freq=d$freq,min.freq = 1,max.words = 100,random.order=FALSE,rot.per=0.35)
wordcloud(words=d$word, freq=d$freq,min.freq = 1,max.words = 100,random.order=FALSE,rot.per=0.35)
library(wordcloud2)
install.packages("wordcloud2")
wordcloud2(d)
library(wordcloud2)
wordcloud2(d)
d
d1=d[1:200,]
wordcloud2(d1,shape='star')
wordcloud2(d1,minRotation = pi/4,maxRotation = pi/4,rotateRatio = 1.0)
findFreqTerms(dtm,lowfreq = 12)
findAssocs(dtm,terms='harvard', corlimit = 0.7)
barplot(d[1:10,]$freq, las=2, names.arg=d[1:10,]$word,col='lightblue', main'발생 빈도 상위 단어', ylab= '단어 빈도')
barplot(d[1:10,]$freq, las=2, names.arg=d[1:10,]$word,col='lightblue', main='발생 빈도 상위 단어', ylab= '단어 빈도')
library(gapminder)
library(dplyr)
pop_siz= gapminder%>%filter(year==2007)%>%group_by(continent)%>%summarize(sum(as.numeric(pop)))
d= data.frame(word=pop_siz[,1],min.freq=1,max.words=100,random.order=FALSE,rot.per=0.35)
wordcloud2(d)
wordcloud(d)
library(text2vec)
install.packages(text2vec)
library(rpart)
library(tm)
library(XML)
library(SnowballC)
library(RCurl)
t=readLines('https://ko.wikipedia.org/wiki/5EB%B9%85_%EB%8D%B0%EC%9D%B4%ED%84%B0')
t=readLines('https://ko.wikipedia.org/wiki/%EB%B9%85_%EB%8D%B0%EC%9D%B4%ED%84%B0')
d=htmlParse(t, asText=TRUE)
clean_doc =xpathSApply(d, "//p",xmlValue)
doc=Corpus(VectorSource(clean_doc))
inspect(doc)
?tm_map
doc=tm_map(doc,content_transformer(tolower))
doc=tm_map(doc,removeNumbers)
doc=tm_map(doc,removePunctuation)
doc=tm_map(doc,stripWhitespace)
dtm=DocumentTermMatrix(doc)
dim(dtm)
inspect(dtm)
?inspect
m=as.matrix(dtm)
v=sort(colSums(m), decresing=TRUE)
v=sort(colSums(m), decreasing=TRUE)
d=data.frame(word=names(v),freq=v)
d1=d[1:500,]
wordcloud2(d1)
?matrix
library(KoNLP)
install.packages("KoNLP")
install.packages("KoNLP")
library(KoNLP)
library(KoNLP)
library(KoNLP)
useSejongDic()
t=readLines('https://ko.wikipedia.org/wiki/%EB%B9%85_%EB%8D%B0%EC%9D%B4%ED%84%B0')
d=htmlParse(t, asText=TRUE)
library(tm)
library(XML)
library(wordcloud2)
library(RCurl)
d=htmlParse(t, asText=TRUE)
clean_doc=xpathSApply(d,"//p",xmlValue)
useSejongDic()
library(stringr)
x=read.csv("C:/Download/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
x=read.csv("C:/Users/cys77/Downloads/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
x$Price = str_replace(x$Price, '\\$','')
x=x[-10473, ]
x$Size = sub("Varies with device", NA, x$Size)
x$Size = sub("M","e6",x$Size, fixed = TRUE)
x$Size = sub("k","e3",x$Size, fixed = TRUE)
x$Size = sub("M","e6",x$Size, fixed = TRUE)
View(x)
x$Size = sub("M","e6",x$Size, fixed = TRUE)
x$Size = sub("M","e7",x$Size, fixed = TRUE)
x$Size = sub("M","e8",x$Size, fixed = TRUE)
x$Size = sub("M","e10",x$Size, fixed = TRUE)
x$Size = sub("M","e5",x$Size, fixed = TRUE)
x$Size = sub("M","e6",x$Size, fixed = TRUE)
x$Size = as.numeric(x$Size)
x$Installs = str_replace(x$Installs,'\\+','')
x$Installs = str_replace_all(x$Installs,'\\+','')
x$Installs=as.numeric(x$Installs)
View(x)
x=na.omit
x=na.omit(x)
View(x)
x
x=read.csv("C:/Users/cys77/Downloads/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
x$Price = str_replace(x$Price, '\\$','')
x=x[-10473, ]
x$Size = sub("Varies with device", NA, x$Size)
x$Size = sub("M","e6",x$Size, fixed = TRUE)
x$Size = as.numeric(x$Size)
x$Installs = str_replace_all(x$Installs,'\\+','')
x$Installs = str_replace(x$Installs,'\\+','')
x$Installs = str_replace(x$Installs,', ','' )
x$Installs = as.numeric(x$Installs)
View(x)
x=na.omit(x)
View(x)
x=read.csv("C:/Users/cys77/Downloads/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
x$Price = str_replace(x$Price, '\\$','')
x=x[-10473, ]
x$Size = sub("Varies with device", NA, x$Size)
x$Size = as.numeric(x$Size)
x$Installs = str_replace(x$Installs, '\\+','')
x$Installs = str_replace_all(x$Installs, ', ','')
x$Installs=as.numeric(x$Installs)
View(x)
x=na.omit(x)
View(ucla)
View(x)
library(dplyr)
glimpse(x)
View(x)
View(x)
rm(list=ls())
library(stringr)
x=read.csv("C:/Users/cys77/Downloads/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
View(x)
x$Price = str_replace(x$Price,'\\$','')
x=x[-10473, ]
x$Size = sub("Varies with device", NA, x$Size)
x$Size = sub("M","e6", x$Size, fixed=TRUE)
View(x)
Sys.setlocale('LC_ALL','C')
x$Size = sub("M","e6", x$Size, fixed=TRUE)
x$Size = sub("k","e3", x$Size, fixed=TRUE)
x$Size=as.numeric(x$Size)
View(x)
x$Installs = str_replace(x$Installs, '\\+','')
x$Installs = str_replace_all(x$Installs, ', ','' )
View(x)
x$Installs=as.numeric(x$Installs)
View(x)
View(x)
x=read.csv("C:/Users/cys77/Downloads/googleplaystore.csv", header = TRUE, sep=",", as.is =TRUE)
x$Price = str_replace(x$Price,'\\$','')
x=x[-10473, ]
x$Size = sub("Varies with device", NA, x$Size)
View(x)
x$Size = sub("M","e6", x$Size, fixed=TRUE)
x$Size = sub("k","e3", x$Size, fixed=TRUE)
x$Size=as.numeric(x$Size)
View(x)
x$Installs = str_replace(x$Installs, '\\+','')
View(x)
x1 =x
x$Installs = str_replace_all(x$Installs, ', ','' )
View(x)
View(x1)
View(x)
x$Installs = str_replace_all(x$Installs, ',','' )
View(x)
x$Installs=as.numeric(x$Installs)
View(x)
x=na.omit(x)
x$Category=as.factor(x$Category)
x$Reviews=as.numeric(x$Reviews)
x$Type=as.factor(x$Type)
x$Price=as.numeric(x$Price)
x$Content.Rating=as.factor(x$Content.Rating)
x$Genres=as.factor(x$Genres)
library(lubridate)
library(lubridate)
x$Last.Updated=mdy(x$Last.Updated)
View(x)
library(dplyr)
glimpse(x)
View(x)
library(ggplot2)
x%>%ggplot(aes(Rating))+geom_histogram()
x%>%ggplot(aes(Rating, fill=Type))+geom_histogram(position="dodge")
x%>%ggplot(aes(Rating,col=Type))+geom_density()
x%>%filter(Type=="Paid"&Price<5)%>%ggplot(aes(Price))+geom_histogram(binwidth = 0.01)
x%>%filter(Type=="Paid"&Price<5)%>%ggplot(aes(Price))+scale_y_log10()+geom_histogram(binwidth = 0.01)
x%>%filter(Type=="Paid")%>%ggplot(aes(Price, Rating))+geom_point(alpha=0.2)
x%>%filter(Type=="Paid")%>%ggplot(aes(Price, Rating))+geom_point(alpha=0.2)+scale_x_log10()
x%>%filter(Type=="Paid"&Price<50)%>%ggplot(aes(Price, Rating))+geom_point(alpha=0.2)
top4 <-x%>%group_by(Category)%>%summarize(n=n())%>%arrange(desc(n))%>%head(4)
View(top4)
top4
x%>%filter(Type=="Paid"&Price<50&Category%in%top4$Category)%>%ggplot(aes(Price,Rating))+geom_point(alpha=0.2)+facet_wrap(~Category)
m=lm(Rating~Size+Content.Rating+Category, data=x)
m
deviance(m)/nrow(x)
library(ggiraphExtra)
library(survival)
str(colon)
p1 =colon%>%ggplot(aes(extent,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
library(dplyr)
p1 =colon%>%ggplot(aes(extent,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
library(ggplot2)
p1 =colon%>%ggplot(aes(extent,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p2 =colon%>%ggplot(aes(age,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p2 =colon%>%ggplot(aes(sex,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p2 =colon%>%ggplot(aes(nodes,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p4 =colon%>%ggplot(aes(nodes,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p3 =colon%>%ggplot(aes(sex,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
p2 =colon%>%ggplot(aes(age,status)) + geom_jitter(aes(col= factor(status)), height=0.1,width=0.1)
ggplot(p1)
plot(p1)
p1
p2
p3
grid.arrange(p1,p2,p3,p4,ncol=2,nrow=2)
library(gridExtra)
install.packages("gridExtra")
library(gridExtra)
library(gridExtra)
grid.arrange(p1,p2,p3,p4,ncol=2,nrow=2)
